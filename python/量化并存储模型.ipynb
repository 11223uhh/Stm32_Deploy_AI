{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1380ce0c",
   "metadata": {},
   "source": [
    "更新之后版本 有相关仿真工具 与STM32实际运行数据一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd465e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该层参数为Q0.7\n",
      "该层参数为Q0.7\n",
      "池化层无法量化\n",
      "该层参数为Q0.7\n",
      "该层参数为Q0.7\n",
      "池化层无法量化\n",
      "该层参数为Q0.7\n",
      "该层参数为Q0.7\n",
      "ROM所需 16.58 KB RAM所需 35.73 KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import d2lzh as d2l\n",
    "from mxnet import gluon, init\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "import mxnet as mx\n",
    "from mxnet.gluon import data as gdata, loss as gloss, model_zoo, nn\n",
    "import os\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "import time\n",
    "\n",
    "def Q_liang(max_data,min_data):\n",
    "    int_bits=0\n",
    "    max_liang=max(abs(max_data),max(min_data))\n",
    "    for i in range(8):\n",
    "        if(max_liang<=2**i):\n",
    "            int_bits=i\n",
    "            break\n",
    "    frac_bits=7-int_bits\n",
    "    return int_bits,frac_bits              \n",
    "\n",
    "def liang(data):\n",
    "    b=data.reshape(1,-1)[0]\n",
    "    min_wt = b.min()[0].asnumpy()\n",
    "    max_wt = b.max() [0].asnumpy()\n",
    "    int_bits,frac_bits = Q_liang(max_wt,min_wt)\n",
    "    print(\"该层参数为Q%s.%s\"%(int_bits,frac_bits))\n",
    "    data_test=nd.round(data*(2**frac_bits))\n",
    "    return data_test\n",
    "    \n",
    "    \n",
    "def INT8_liang(data):\n",
    "    data_INT=liang(data)      #数据量化             \n",
    "    data_INT=data_INT.astype(\"int8\") #量化 INT8必须\n",
    "    data_INT=data_INT.astype(\"float32\") #为了python计算\n",
    "    return data_INT\n",
    "\n",
    "#计算模型输入输出量并存储形状\n",
    "shift_count=0\n",
    "\n",
    "def get_net_cicun(X_shape,y_shape,i,count,f,BIAS_LSHIFT,OUT_RSHIFT):\n",
    "    str_temp=str(i)\n",
    "    global shift_count\n",
    "    cneg_name=str_temp.split(\"(\")[0]\n",
    "    if(cneg_name==\"Conv2D\"):\n",
    "        \n",
    "        name=str(i.name_scope).split(\"<bound method Block.name_scope of\")[1][1:]\n",
    "\n",
    "        name=name.split(\"(\")[0]+\"_\"+str(count)\n",
    "        CONV_IM_DIM =X_shape[2]\n",
    "        CONV_IM_CH =X_shape[1]\n",
    "        \n",
    "        CONV_OUT_DIM=y_shape[2]\n",
    "        CONV_OUT_CH=y_shape[1]\n",
    "        \n",
    "        CONV_KER_DIM=str_temp.split(\"kernel_size=(\")[1]\n",
    "        CONV_KER_DIM=CONV_KER_DIM.split(\",\")[0]\n",
    "        CONV_STRIDE=str_temp.split(\"stride=(\")[1]\n",
    "        CONV_STRIDE=CONV_STRIDE.split(\",\")[0]\n",
    "        try:\n",
    "            CONV_PADDING=str_temp.split(\"padding=(\")[1]\n",
    "            CONV_PADDING=CONV_PADDING.split(\",\")[0]\n",
    "        except:\n",
    "            CONV_PADDING=0\n",
    "         \n",
    "        temp=str(\"#define CONV_IM_DIM\")+\"_\"+str(count)+\" \"+str(CONV_IM_DIM)+\"\\n\"\n",
    "        f.write(temp)\n",
    "        temp=str(\"#define CONV_IM_CH\")+\"_\"+str(count)+\" \"+str(CONV_IM_CH)+\"\\n\"\n",
    "        f.write(temp)\n",
    "        temp=str(\"#define CONV_OUT_DIM\")+\"_\"+str(count)+\" \"+str(CONV_OUT_DIM)+\"\\n\"\n",
    "        f.write(temp)\n",
    "        temp=str(\"#define CONV_OUT_CH\")+\"_\"+str(count)+\" \"+str(CONV_OUT_CH)+\"\\n\"\n",
    "        f.write(temp)\n",
    "        temp=str(\"#define CONV_KER_DIM\")+\"_\"+str(count)+\" \"+str(CONV_KER_DIM)+\"\\n\"\n",
    "        f.write(temp)\n",
    "        temp=str(\"#define CONV_STRIDE\")+\"_\"+str(count)+\" \"+str(CONV_STRIDE)+\"\\n\"\n",
    "        f.write(temp)\n",
    "        temp=str(\"#define CONV_PADDING\")+\"_\"+str(count)+\" \"+str(CONV_PADDING)+\"\\n\"\n",
    "        f.write(temp)\n",
    "        \n",
    "        str1=name+\"_BIAS_LSHIFT\"+str(\"_\")+str(count)\n",
    "        temp=\"#define %s\"%str1+str(\" \")+str(BIAS_LSHIFT[shift_count])+\"\\n\"\n",
    "        f.write(temp)\n",
    "        str1=name+\"_OUT_RSHIFT\"+str(\"_\")+str(count)\n",
    "        temp=\"#define %s\"%str1+str(\" \")+str(OUT_RSHIFT[shift_count])+\"\\n\"+\"\\n\"\n",
    "        f.write(temp)\n",
    "        shift_count=shift_count+1\n",
    "        \n",
    "    if(cneg_name==\"Dense\"):\n",
    "        name=str(i.name_scope).split(\"<bound method Block.name_scope of\")[1][1:]\n",
    "\n",
    "        name=name.split(\"(\")[0]+\"_\"+str(count)\n",
    "        try:\n",
    "            IP1_DIM=X_shape[1]*X_shape[2]*X_shape[2]\n",
    "        except:\n",
    "            IP1_DIM=X_shape[1]\n",
    "        temp=str(\"#define IP1_DIM\")+\"_\"+str(count)+\" \"+str(IP1_DIM)+\"\\n\"\n",
    "        f.write(temp)\n",
    "        \n",
    "        IP1_OUT=y_shape[1]\n",
    "        temp=str(\"#define IP1_OUT\")+\"_\"+str(count)+\" \"+str(IP1_OUT)+\"\\n\"\n",
    "        f.write(temp)\n",
    "        \n",
    "        str1=name+\"_BIAS_LSHIFT\"+str(\"_\")+str(count)\n",
    "        temp=\"#define %s\"%str1+str(\" \")+str(BIAS_LSHIFT[shift_count])+\"\\n\"\n",
    "        f.write(temp)\n",
    "        str1=name+\"_OUT_RSHIFT\"+str(\"_\")+str(count)\n",
    "        temp=\"#define %s\"%str1+str(\" \")+str(OUT_RSHIFT[shift_count])+\"\\n\"+\"\\n\"\n",
    "        f.write(temp)\n",
    "        shift_count=shift_count+1\n",
    "\n",
    "    if(cneg_name==\"MaxPool2D\"):\n",
    "        POOL1_KER_DIM=str_temp.split(\"size=(\")[1]\n",
    "        POOL1_KER_DIM= POOL1_KER_DIM.split(\",\")[0]\n",
    "        POOL1_STRIDE=str_temp.split(\"stride=(\")[1]\n",
    "        POOL1_STRIDE=POOL1_STRIDE.split(\",\")[0]\n",
    "        POOL1_PADDING=str_temp.split(\"padding=(\")[1]\n",
    "        POOL1_PADDING=POOL1_PADDING.split(\",\")[0]\n",
    "        POOL1_OUT_DIM=y_shape[2]\n",
    "        \n",
    "        temp=str(\"#define POOL_OUT_DIM\")+\"_\"+str(count)+\" \"+str(POOL1_OUT_DIM)+\"\\n\"\n",
    "        f.write(temp)\n",
    "        temp=str(\"#define POOL_KER_DIM\")+\"_\"+str(count)+\" \"+str(POOL1_KER_DIM)+\"\\n\"\n",
    "        f.write(temp)\n",
    "        temp=str(\"#define POOL_STRIDE\")+\"_\"+str(count)+\" \"+str(POOL1_STRIDE)+\"\\n\"\n",
    "        f.write(temp)\n",
    "        temp=str(\"#define POOL_PADDING\")+\"_\"+str(count)+\" \"+str(POOL1_PADDING)+\"\\n\"\n",
    "        f.write(temp)\n",
    "        \n",
    "        \n",
    "#计算位移并存储位移\n",
    "def get_net_shift(X,net,f,BIAS_LSHIFT,OUT_RSHIFT):\n",
    "    count=0\n",
    "    for layer in net:\n",
    "        name=layer.name[0:4]\n",
    "        output=layer(X)\n",
    "        get_net_cicun(X.shape,output.shape,layer,count,f,BIAS_LSHIFT,OUT_RSHIFT)\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "        X=output\n",
    "        count=count+1\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def liang_print(net,X,BIAS_LSHIFT,f):\n",
    "\n",
    "    count=0\n",
    "    name_count=0\n",
    "\n",
    "    for layer in net:\n",
    "        str_temp=str(layer)\n",
    "        cneg_name=str_temp.split(\"(\")[0]\n",
    "        if(cneg_name==\"Conv2D\"):\n",
    "            name=str(layer.name_scope).split(\"<bound method Block.name_scope of\")[1][1:]\n",
    "\n",
    "            name=name.split(\"(\")[0]+\"_\"+str(name_count)\n",
    "            weight=layer.weight.data()\n",
    "            if(count>0):\n",
    "                d1=weight.swapaxes(1,2)\n",
    "                d2=d1.swapaxes(2,3)\n",
    "                data=d2.reshape(1,-1)[0]\n",
    "            else:\n",
    "                data=weight.reshape(1,-1)[0]\n",
    "\n",
    "            temp2 = ','.join(str(int(i.asnumpy())) for i in data)\n",
    "            temp=\"#define %s\"%(name+\"_weight\")+\" {\"+temp2+\"}\"+\"\\n\\n\"\n",
    "            f.write(temp)\n",
    "\n",
    "            bias=layer.bias.data().reshape(1,-1)[0]\n",
    "            bias  =bias/(2**(BIAS_LSHIFT[count]))\n",
    "            bias=nd.round(bias)\n",
    "            temp2 = ','.join(str(int(i.asnumpy())) for i in bias)\n",
    "            temp=\"#define %s\"%(name+\"_bias\")+\" {\"+temp2+\"}\"+\"\\n\\n\"\n",
    "\n",
    "            f.write(temp)\n",
    "            name_count=name_count+1\n",
    "            count=count+1\n",
    "        if(cneg_name==\"Dense\"):\n",
    "            name=str(layer.name_scope).split(\"<bound method Block.name_scope of\")[1][1:]\n",
    "\n",
    "            name=name.split(\"(\")[0]+\"_\"+str(name_count)\n",
    "            shape=[0,0,0,0]\n",
    "            shape[0]=net[-1].bias.data().shape[0]\n",
    "            shape[1:]=X.shape[1:]\n",
    "            \n",
    "            weight=layer.weight.data()\n",
    "            weight=weight.reshape(shape)\n",
    "            d1=weight.swapaxes(1,2)\n",
    "            d2=d1.swapaxes(2,3)\n",
    "            data=d2.reshape(1,-1)[0]\n",
    "            temp2 = ','.join(str(int(i.asnumpy())) for i in data)\n",
    "            temp=\"#define %s\"%(name+\"_weight\")+\" {\"+temp2+\"}\"+\"\\n\\n\"\n",
    "            f.write(temp)\n",
    "            bias=layer.bias.data().reshape(1,-1)[0]\n",
    "            bias  =bias/(2**(BIAS_LSHIFT[count]))\n",
    "            bias=nd.round(bias)\n",
    "            temp2 = ','.join(str(int(i.asnumpy())) for i in bias)\n",
    "            temp=\"#define %s\"%(name+\"_bias\")+\" {\"+temp2+\"}\"+\"\\n\\n\"\n",
    "            f.write(temp)\n",
    "            count=count+1\n",
    "            name_count=name_count+1\n",
    "\n",
    "        X = layer(X)\n",
    "\n",
    "\n",
    "\n",
    "#采用最大量化\n",
    "def INT8_net_pranms_Init(net,BIAS_LSHIFT):\n",
    "    count=0\n",
    "    for layer in net:\n",
    "        try:\n",
    "            w_data=layer.weight.data()\n",
    "            b_data=layer.bias.data()\n",
    "            \n",
    "            w_data_INT8=INT8_liang(w_data)\n",
    "            b_data_INT8=INT8_liang(b_data)\n",
    "            b_data_INT8  =b_data_INT8*(2**(BIAS_LSHIFT[count]))\n",
    "            #print(b_data_INT8)\n",
    "            count=count+1\n",
    "            layer.weight.set_data(w_data_INT8)\n",
    "            layer.bias.  set_data(b_data_INT8)\n",
    "        except:\n",
    "            print(\"池化层无法量化\")\n",
    "    return net\n",
    "\n",
    "\n",
    "def net_get_data(X,file,net,BIAS_LSHIFT,OUT_RSHIFT):\n",
    "    \n",
    "    f = open(file, 'a+')\n",
    "    get_net_shift(X,net,f,BIAS_LSHIFT,OUT_RSHIFT)\n",
    "    liang_print(net,X,BIAS_LSHIFT,f)\n",
    "    name_count=0\n",
    "    f.close()\n",
    "def RAM_ROM_calculate(X,net):\n",
    "    data_len=0\n",
    "    count=0\n",
    "    for layer in net:\n",
    "        output=layer(X)\n",
    "        try:\n",
    "            w_data=layer.weight.data()\n",
    "            w_data=w_data.reshape(1,-1)[0]\n",
    "            b_data=layer.bias.data()\n",
    "            \n",
    "            b_data=b_data.reshape(1,-1)[0]\n",
    "            #print(w_data.shape[0])\n",
    "            data_len=data_len+w_data.shape[0]+b_data.shape[0]\n",
    "            if(count==0):\n",
    "                data_len2=(X.reshape(1,-1)[0]).shape[0]+(output.reshape(1,-1)[0]).shape[0]\n",
    "            count=count+1\n",
    "\n",
    "        except:\n",
    "            c=3\n",
    "           \n",
    "                \n",
    "        X=output\n",
    "    ROM=data_len/1024\n",
    "    ROM_str1=\"ROM所需 \"+str(ROM)[0:5]+\" KB\"\n",
    "    \n",
    "    RAM=data_len2/1024+ROM\n",
    "    RAM_str1=\"RAM所需 \"+str(RAM)[0:5]+\" KB\"\n",
    "\n",
    "    print(ROM_str1,RAM_str1)\n",
    "###########################################################################用户自定义代码\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Conv2D(channels=1, kernel_size=3, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        # Dense会默认将(批量大小, 通道, 高, 宽)形状的输入转换成\n",
    "        # (批量大小, 通道 * 高 * 宽)形状的输入\n",
    "        nn.Conv2D(channels=4, kernel_size=3, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Dense(8))\n",
    "net.load_parameters(\"D:/traint__minst_as\")\n",
    "X=nd.zeros((1,1,100,100))\n",
    "BIAS_LSHIFT=[6,5,5]\n",
    "OUT_RSHIFT =[9,9,8]\n",
    "net_int8=INT8_net_pranms_Init(net,BIAS_LSHIFT)\n",
    "RAM_ROM_calculate(X,net)\n",
    "net_get_data(X,\"D://mnist_adin_5.txt\",net_int8,BIAS_LSHIFT,OUT_RSHIFT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
