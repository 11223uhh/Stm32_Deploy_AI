{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ffb61d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该层参数为Q0.7\n",
      "该层参数为Q0.7\n",
      "池化层无法量化\n",
      "该层参数为Q0.7\n",
      "该层参数为Q0.7\n",
      "池化层无法量化\n",
      "该层参数为Q0.7\n",
      "该层参数为Q0.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import gluon, init\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "import mxnet as mx\n",
    "from mxnet.gluon import data as gdata, loss as gloss, model_zoo, nn\n",
    "import os\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "import time\n",
    "from mxnet.gluon import HybridBlock\n",
    "from mxnet.image import  Augmenter\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Q_liang(max_data,min_data):\n",
    "    int_bits=0\n",
    "    max_liang=max(abs(max_data),max(min_data))\n",
    "    for i in range(8):\n",
    "        if(max_liang<=2**i):\n",
    "            int_bits=i\n",
    "            break\n",
    "    frac_bits=7-int_bits\n",
    "    return int_bits,frac_bits              \n",
    "\n",
    "def liang(data):\n",
    "    b=data.reshape(1,-1)[0]\n",
    "    min_wt = b.min()[0].asnumpy()\n",
    "    max_wt = b.max() [0].asnumpy()\n",
    "    int_bits,frac_bits = Q_liang(max_wt,min_wt)\n",
    "    print(\"该层参数为Q%s.%s\"%(int_bits,frac_bits))\n",
    "    data_test=nd.round(data*(2**frac_bits))\n",
    "    return data_test\n",
    "    \n",
    "    \n",
    "def INT8_liang(data):\n",
    "    data_INT=liang(data)      #数据量化             \n",
    "    data_INT=data_INT.astype(\"int8\") #量化 INT8必须\n",
    "    data_INT=data_INT.astype(\"float32\") #为了python计算\n",
    "    return data_INT\n",
    "\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Conv2D(channels=1, kernel_size=3, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        # Dense会默认将(批量大小, 通道, 高, 宽)形状的输入转换成\n",
    "        # (批量大小, 通道 * 高 * 宽)形状的输入\n",
    "        nn.Conv2D(channels=4, kernel_size=3, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Dense(8))\n",
    "\n",
    "\n",
    "net.load_parameters(\"D:/traint__minst_as\")\n",
    "#采用最大量化\n",
    "\n",
    "def INT_8_net_4_test_s(net,X,OUT_RSHIFT):\n",
    "    global ouput1\n",
    "    ouput_shift=0\n",
    "    bias_shift=0\n",
    "    X=X.astype(\"int8\")\n",
    "    X=X.astype(\"float32\") #为了python计算\n",
    "    count=0\n",
    "    for layer in net:\n",
    "        str_temp=str(layer)\n",
    "        cneg_name=str_temp.split(\"(\")[0]\n",
    "        if(cneg_name==\"Conv2D\")or(cneg_name==\"Dense\"):\n",
    "            ouput_shift=OUT_RSHIFT[count]\n",
    "            ouput_shift=2**ouput_shift\n",
    "            X=layer(X)\n",
    "            #print(X.max(),layer)\n",
    "            X=X/ouput_shift                                   #输出偏移\n",
    "            X=nd.round(X)\n",
    "            #print(X.max())\n",
    "            X=X.astype(\"int8\")\n",
    "            if(count==1):\n",
    "                ouput1=X\n",
    "            X=X.astype(\"float32\")\n",
    "            count=count+1\n",
    "        else:\n",
    "            X=layer(X)\n",
    "            X=X.astype(\"int8\")\n",
    "            X=X.astype(\"float32\")\n",
    "    return X\n",
    "# X=Image.open(\"C:\\\\Users\\\\胡程畅\\\\Desktop\\\\test_picture\\\\0.jpg\")\n",
    "# X_array=nd.array(X)\n",
    "# X_array=X_array/255\n",
    "# X_array=nd.round(X_array*127).reshape((1,1,28,28))\n",
    "\n",
    "# result=INT_8_net_4(net_int8,X_array)\n",
    "# result,result.argmax(axis=1)\n",
    "\n",
    "\n",
    "data_dir  ='D:\\mnist_2'\n",
    "transform_train = gdata.vision.transforms.Compose([\n",
    "    # 随机对图像裁剪出面积为原图像面积0.08~1倍、且高和宽之比在3/4~4/3的图像，再放缩为高和\n",
    "    # 宽均为224像素的新图像\n",
    "    gdata.vision.transforms.Resize(120),\n",
    "    gdata.vision.transforms.CenterCrop(100),\n",
    "\n",
    "    # 随机加噪声\n",
    "    gdata.vision.transforms.ToTensor()\n",
    "    # 对图像的每个通道做标准化\n",
    "   ])\n",
    "batch_size=100\n",
    "train_ds = gdata.vision.ImageFolderDataset(\n",
    "         os.path.join(data_dir, 'train2'), flag=0)\n",
    "\n",
    "train_iter = gdata.DataLoader(train_ds.transform_first(transform_train),\n",
    "                              batch_size, shuffle=True, last_batch='keep')\n",
    "\n",
    "\n",
    "BIAS_LSHIFT=[6,7,6]\n",
    "OUT_RSHIFT =[9,9,8]\n",
    "\n",
    "net_int8=INT8_net_pranms_Init(net,BIAS_LSHIFT)\n",
    "def net_Int8_evaluate_accuracy(data_iter, ctx):\n",
    "    acc_sum, n = 0.00, 0\n",
    "    for X, y in data_iter:\n",
    "        y = y.astype('float32')\n",
    "        y = y.as_in_context(ctx)\n",
    "        X=nd.round(X*127)\n",
    "        outputs = INT_8_net_4_test_s(net_int8,X.as_in_context(ctx),OUT_RSHIFT)\n",
    "        acc_sum += (outputs.argmax(axis=1) == y).sum().copyto(mx.cpu())\n",
    "        n += y.size\n",
    "        acc_sum.wait_to_read()\n",
    "    return acc_sum.asscalar() / n\n",
    "\n",
    "net_Int8_evaluate_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf61050",
   "metadata": {},
   "source": [
    "获取输出偏移值和偏差偏移值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48cd31e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9794871794871794"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Conv2D(channels=4, kernel_size=3, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        # Dense会默认将(批量大小, 通道, 高, 宽)形状的输入转换成\n",
    "        # (批量大小, 通道 * 高 * 宽)形状的输入\n",
    "        nn.Conv2D(channels=4, kernel_size=3, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        nn.Dense(8))\n",
    "\n",
    "net.load_parameters(\"D:/traint__minst_as\")\n",
    "acc1=d2l.evaluate_accuracy(train_iter,net,mx.cpu())\n",
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbecb0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('96.42%', 0.9642324888226528)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc3=str(acc*100)[0:5]+\"%\"\n",
    "acc3,acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fc7f889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1=ouput1.swapaxes(1,2)\n",
    "d2=d1.swapaxes(2,3)\n",
    "d3=d2.reshape((1,-1))[0]\n",
    "\n",
    "result=nd.array([3,0,0,0,3,0,0,0,3,0,0,0,8,0,4,0,24,0,31,16,30,21,57,24,44,54,28,26,60,47,0,21,51,34,0,2,27,23,0,0,7,7,0,0,3,0,0,0,3,0,0,0,10,0,6,2,27,0,35,18,22,27,65,23,15,55,48,30,0,46,6,39,0,35,0,49,6,18,0,32,21,23,0,2,17,17,0,0,3,0,0,0,7,0,2,0,18,0,35,16,14,24,70,25,6,50,41,27,0,41,1,41,0,22,0,46,0,12,0,55,0,11,0,51,0,13,0,17,14,16,0,0,4,0,0,0,17,0,24,13,8,17,68,21,0,46,43,27,0,37,0,31,0,10,0,28,0,0,0,32,0,0,20,47,0,0,21,56,0,10,0,28,7,19,0,0,11,0,9,4,6,8,60,19,0,27,56,22,0,30,0,19,0,0,0,23,0,0,0,18,0,0,0,10,0,0,54,25,0,2,45,47,0,12,0,33,0,12,0,2,3,3,28,11,0,12,77,23,0,20,8,24,0,0,0,16,0,0,0,13,0,0,0,5,0,0,5,5,0,0,82,14,0,15,36,35,0,11,0,33,0,7,0,9,0,3,44,9,0,5,63,28,0,0,0,29,0,0,0,16,0,0,0,5,12,0,12,7,24,2,36,13,4,27,65,10,0,37,0,20,0,6,0,29,0,0,0,14,0,0,49,7,0,0,55,32,0,0,0,40,4,0,0,22,33,9,13,12,40,30,32,13,26,55,32,15,0,50,3,10,0,9,0,16,0,0,0,21,0,0,0,7,0,0,46,7,0,6,54,36,0,14,0,58,14,34,3,43,36,62,18,27,20,72,10,22,0,55,0,20,0,4,0,21,0,0,0,17,0,0,0,7,0,0,0,0,0,3,33,0,0,11,36,24,0,17,6,60,0,36,0,61,0,45,0,41,0,19,0,30,0,0,0,25,0,0,0,18,0,0,0,7,0,0,0,0,3,0,0,0,0,0,13,0,0,0,17,0,0,0,0,16,0,0,0,30,0,0,0,29,0,0,0,21,0,0,0,12,0,0,0,2,0,0,0,0,3,0,0,0,3,0,0,0,])\n",
    "start=300\n",
    "result.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306f83ef",
   "metadata": {},
   "source": [
    "仿真的结果和实际结果有细微偏差，这是由于CMSIS-NN的四舍五入算法有点问题，对于负数其四舍五入逻辑为\n",
    "\n",
    "小数部分的绝对值大于0.5小数-1，等于0.5不变，这和标准的四舍五入有区别。举个例子\n",
    "\n",
    "-3.5 CMSIS 四舍五入 -3\n",
    "     标准  四舍五入 -4\n",
    "-3.7 CMSIS 四舍五入 -4\n",
    "     标准  四舍五入 -4\n",
    "-3.2 CMSIS 四舍五入 -3\n",
    "     标准  四舍五入 -3\n",
    "     \n",
    "可以自行修改 CMSIS的四舍五入但不推荐,因为有Relu激活函数 负数不管什么四舍五入直接归零。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1505c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
